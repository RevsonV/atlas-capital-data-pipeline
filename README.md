# üìä **Atlas Capital: Pipeline ELT e Modelagem de Indicadores Macroecon√¥micos**

---

##üí° **Cen√°rio de Neg√≥cio**

Atlas Capital √© uma empresa <u>fict√≠cia</u>, um pequeno fundo de investimentos focado em mercados emergentes. Seu time de an√°lise sofria com a fragmenta√ß√£o de dados, perdendo cerca de 60% do tempo na coleta manual de dados dos pa√≠ses alvo.

**Objetivo:** Construir um "sistema de fornecimento de dados" automatizado, transformando dados brutos em um modelo anal√≠tico robusto para monitoramento de PIB, Infla√ß√£o e Desemprego em tempo real. Sem or√ßamento dispon√≠vel para tal, a busca por uma solu√ß√£o de custo zero √© a prioridade.

---

##üèóÔ∏è **Arquitetura do Projeto (Modern Data Stack)**

O projeto segue o paradigma ELT (Extract, Load, Transform), priorizando o processamento dentro do Data Warehouse para escalabilidade e baixo custo.

**Fluxo:** World Bank API ‚û°Ô∏è Python (Ingest√£o) ‚û°Ô∏è BigQuery (Raw) ‚û°Ô∏è dbt Core (Transforma√ß√£o) ‚û°Ô∏è Looker Studio (BI)
![Lineage graph](image.png)

---

##‚öôÔ∏è **Stack Tecnol√≥gica**

| Componente     | Tecnologia      | Papel no Pipeline                                                  |
|:---------------|:----------------|:-------------------------------------------------------------------|
| Linguagem      | Python 3.12     | Scripts de extra√ß√£o de API e carga resiliente.                     |
| Data Warehouse | Google BigQuery | Armazenamento colunar em nuvem (Camadas Raw, Staging e Marts).     |
| Transforma√ß√£o  | dbt Core        | Engenharia Anal√≠tica, modelagem dimensional e testes de qualidade. |
| Orquestra√ß√£o   | GitHub Actions  | Automa√ß√£o di√°ria (Cron Job) e integra√ß√£o cont√≠nua (CI/CD).         |
| Infraestrutura | Terraform       | Defini√ß√£o da arquitetura de datasets como c√≥digo (IaC).            |
| Visualiza√ß√£o   | Looker Studio   | Dashboard executivo para tomada de decis√£o.                        |

---

##üöÄ **Detalhes T√©cnicos e Engenharia**

1. **Ingest√£o (Python)**
* Extra√ß√£o de 5 indicadores macroecon√¥micos para 6 pa√≠ses emergentes.
* **Resili√™ncia:** Tratamento de erros de API e loops iterativos para contornar limita√ß√µes de endpoints p√∫blicos.
* **Idempot√™ncia:** Cargas configuradas para garantir que execu√ß√µes repetidas n√£o dupliquem dados.
2. **Modelagem de Dados (dbt Core)**
* **Arquitetura de Medalh√£o:** Organiza√ß√£o em camadas stg_ (limpeza), dim_ (dimens√µes) e fact_ (fatos).
* **Star Schema:** Implementa√ß√£o de tabelas dimensionais (dim_pais, dim_tempo) e tabela fato pivoteada para alta performance em BI.
* **Data Quality:** 10/10 testes aprovados (Unique, Not Null e Referential Integrity).
3. **Automa√ß√£o (CI/CD)**
* Pipeline configurado no GitHub Actions para rodar diariamente sem interven√ß√£o manual.
* Inje√ß√£o din√¢mica de segredos (GCP Service Account) via Base64 para m√°xima seguran√ßa.

---

##‚úÖ **Resultados**

* **Situa√ß√£o:** Decis√µes de investimento baseadas em processos manuais e dados n√£o validados.
* **Tarefa:** Automatizar o fluxo fim a fim com custo zero de infraestrutura.
* **A√ß√£o:** Implementei um pipeline ELT completo integrando Python, BigQuery e dbt com automa√ß√£o via GitHub Actions.
* **Resultado:** Redu√ß√£o de 100% no esfor√ßo manual de coleta e 100% de confian√ßa nos dados atrav√©s de testes automatizados.

---

##üîó **Links e Artefatos**

* **Dashboard Interativo:** https://lookerstudio.google.com/reporting/b6ce62da-b856-4e12-a64c-80e30c5c75a8
* **Documenta√ß√£o dbt (Lineage):** https://revsonv.github.io/atlas-capital-data-pipeline/#!/overview
* **Perfil no LinkedIn:** https://www.linkedin.com/in/revson-vieira-0a753057/

---

##üõ†Ô∏è **Como Reproduzir**

1. Clone o reposit√≥rio.
2. Configure as credenciais do GCP no arquivo .env (local) ou GitHub Secrets.
3. Execute pip install -r requirements.txt.
4. Rode o script de ingest√£o: python src/ingestion_pipeline.py.
5. Execute as transforma√ß√µes: dbt run e dbt test.

*Desenvolvido por Revson Vieira como projeto de portf√≥lio para Engenharia de Dados.*